{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from scipy.optimize import curve_fit\n",
    "# sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data in from checkpoint files\n",
    "data_sequences = []\n",
    "for lf in os.listdir(\"checkpoints\"):\n",
    "    with open(f\"checkpoints/{lf}/log.txt\") as f:\n",
    "        data = f.readlines()\n",
    "        run_name = lf.rstrip(\"-0123456789\")\n",
    "        loss_sequence = np.array([float(l.split(',')[2].split(':')[1]) for l in data])\n",
    "        data_sequences.append((run_name, loss_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_LEN = len(data_sequences[0][1])\n",
    "TAIL_LEN = RUN_LEN // 20\n",
    "\n",
    "# get the section of loss from the last half of the final epoch\n",
    "mean_final_losses = [(rn, np.mean(ls[-TAIL_LEN:])) for rn, ls in data_sequences]\n",
    "\n",
    "min_loss = 100.0\n",
    "max_loss = -1.0\n",
    "for _, loss in mean_final_losses:\n",
    "    min_loss = min(min_loss, loss)\n",
    "    max_loss = max(max_loss, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract number of neurons and configuration name\n",
    "def parse_name(name) -> tuple[int, str]:\n",
    "    mtch = re.search(r'(\\d+)n$', name)\n",
    "    if mtch is None:\n",
    "        print(\"Error! No match!\")\n",
    "        return 0, \"\"\n",
    "    neurons = int(mtch.group(1))\n",
    "    config = re.sub(r'-\\d+n$', '', name)\n",
    "    config = re.sub(\"optimiser-benchmark-\", '', config)\n",
    "    return neurons, config.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse data\n",
    "tagged_data = [(parse_name(name), loss) for name, loss in mean_final_losses]\n",
    "\n",
    "# Group data by number of neurons\n",
    "grouped_data: dict[int, list[tuple[str, np.float64]]] = {}\n",
    "for (neurons, config), loss in tagged_data:\n",
    "    if neurons not in grouped_data:\n",
    "        grouped_data[neurons] = [] # type: ignore\n",
    "    grouped_data[neurons].append((config, loss))\n",
    "\n",
    "# Sort all the subgroups.\n",
    "for k in grouped_data:\n",
    "    grouped_data[k].sort(key = lambda t: t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare plot data\n",
    "neuron_counts = sorted(grouped_data.keys())\n",
    "x = np.arange(len(neuron_counts))\n",
    "n_configs = len(grouped_data[neuron_counts[0]])\n",
    "width = 0.2 * 4 / n_configs\n",
    "# Populate a colours map\n",
    "config_colors = {}\n",
    "palette = sns.color_palette()\n",
    "for i, k in enumerate(grouped_data[1]):\n",
    "    config_colors[k[0]] = palette[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for i, neuron_count in enumerate(neuron_counts):\n",
    "    for j, (config, loss) in enumerate(grouped_data[neuron_count]):\n",
    "        color = config_colors[config]\n",
    "        label = config if i == 0 else \"\"\n",
    "        ax.bar(x[i] + j*width, loss, width, label=label, color=color)\n",
    "\n",
    "# Customize plot\n",
    "ax.set_yscale(\"log\", base = 2)\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Number of Neurons')\n",
    "ax.set_title('Neural Network Configurations: Loss Comparison')\n",
    "ax.set_xticks(x + width * (n_configs - 1) / 2)\n",
    "ax.set_xticklabels(neuron_counts)\n",
    "y_ticks = np.logspace(np.log2(min_loss), np.log2(max_loss), num = 15, base = 2.0)\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(np.round(y_ticks, 4))\n",
    "ax.legend(title=\"Configuration\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataset for plotting linearly.\n",
    "configuration_series: dict[str, list[tuple[int, np.float64]]] = {}\n",
    "for config, _ in grouped_data[1]:\n",
    "    xs = []\n",
    "    for _, neuron_count in enumerate(neuron_counts):\n",
    "        for _, (inner_config, loss) in enumerate(grouped_data[neuron_count]):\n",
    "            if config == inner_config:\n",
    "                xs.append((neuron_count, loss))\n",
    "    configuration_series[config] = xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "min_loss = 100.0\n",
    "max_loss = -1.0\n",
    "for config, seq in configuration_series.items():\n",
    "    x, y = zip(*seq)\n",
    "    min_loss = min(min_loss, np.min(y))\n",
    "    max_loss = max(max_loss, np.max(y))\n",
    "    ax.plot(x, y, label = config, marker = '+')\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xscale(\"log\", base = 2)\n",
    "ax.set_yscale(\"log\", base = 2)\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Number of Neurons')\n",
    "ax.set_title('Neural Network Configurations: Loss Comparison')\n",
    "ax.set_xticks([2 ** x for x in range(0, 14)])\n",
    "ax.set_xticklabels([2 ** x for x in range(0, 14)])\n",
    "ax.set_xlim(0.5, 8192)\n",
    "y_ticks = np.logspace(np.log2(min_loss), np.log2(max_loss), num = 15, base = 2.0)\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(np.round(y_ticks, 4))\n",
    "ax.legend(title=\"Configuration\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "SKIP = 4\n",
    "\n",
    "min_loss = 100.0\n",
    "max_loss = -1.0\n",
    "for config, seq in configuration_series.items():\n",
    "    x, y = zip(*seq[SKIP:])\n",
    "    min_loss = min(min_loss, np.min(y))\n",
    "    max_loss = max(max_loss, np.max(y))\n",
    "    ax.plot(x, y, label = config, marker = '+')\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xscale(\"log\", base = 2)\n",
    "ax.set_yscale(\"log\", base = 2)\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Number of Neurons')\n",
    "ax.set_title('Neural Network Configurations: Loss Comparison')\n",
    "x_ticks = [2 ** x for x in range(SKIP, 14)]\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.set_xticklabels(x_ticks)\n",
    "ax.set_xlim(x_ticks[0] / 2.0, 8192)\n",
    "y_ticks = np.logspace(np.log2(min_loss), np.log2(max_loss), num = 15, base = 2.0)\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(np.round(y_ticks, 4))\n",
    "ax.legend(title=\"Configuration\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "SKIP = 7\n",
    "\n",
    "min_loss = 100.0\n",
    "max_loss = -1.0\n",
    "desired_configs = [\n",
    "    \"screlu\", \"screlu-lineardecay\", \"screlu-warmup256\", \"screlu-warmupcosinedecay\"\n",
    "]\n",
    "for config, seq in configuration_series.items():\n",
    "    if config not in desired_configs:\n",
    "        continue\n",
    "    x, y = zip(*seq[SKIP:])\n",
    "    min_loss = min(min_loss, np.min(y))\n",
    "    max_loss = max(max_loss, np.max(y))\n",
    "    ax.plot(x, y, label = config, marker = '+')\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xscale(\"log\", base = 2)\n",
    "ax.set_yscale(\"log\", base = 2)\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Number of Neurons')\n",
    "ax.set_title('Neural Network Configurations: Loss Comparison')\n",
    "x_ticks = [2 ** x for x in range(SKIP, 14)]\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.set_xticklabels(x_ticks)\n",
    "ax.set_xlim(x_ticks[0] / 2.0, 8192)\n",
    "y_ticks = np.logspace(np.log2(min_loss), np.log2(max_loss), num = 15, base = 2.0)\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(np.round(y_ticks, 4))\n",
    "ax.legend(title=\"Configuration\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a power-law model to the screlu data, and plot it alongside the data.\n",
    "def powlaw(x, a, b, c) :\n",
    "    return a * np.power(x, b) + c\n",
    "\n",
    "screlu_neuron_counts, screlu_losses = zip(*configuration_series[\"screlu\"])\n",
    "\n",
    "def model(x, y):\n",
    "    popt, pcov = curve_fit(powlaw, x, y, p0 = np.array([1.0, -1.0, 1.0]), maxfev=2000)\n",
    "    extrap = list(screlu_neuron_counts) + [2048, 4096]\n",
    "    return extrap, powlaw(extrap, *popt), popt\n",
    "\n",
    "extrap_inputs, screlu_extrap, screlu_params = model(screlu_neuron_counts, screlu_losses)\n",
    "\n",
    "crelu_neuron_counts, crelu_losses = zip(*configuration_series[\"crelu\"])\n",
    "\n",
    "extrap_inputs, crelu_extrap, crelu_params = model(crelu_neuron_counts, crelu_losses)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_xscale(\"log\", base = 2)\n",
    "ax.set_yscale(\"log\", base = 2)\n",
    "ax.plot(extrap_inputs, screlu_extrap, '--', label = \"screlu-model\")\n",
    "ax.plot(screlu_neuron_counts, screlu_losses, 'x', label = \"optimiser-benchmark-screlu datapoints\")\n",
    "ax.plot(extrap_inputs, crelu_extrap, '--', label = \"crelu-model\")\n",
    "ax.plot(crelu_neuron_counts, crelu_losses, 'x', label = \"optimiser-benchmark-crelu datapoints\")\n",
    "\n",
    "screlu_text = f\"screlu: y = {screlu_params[0]:.2e} * x^{screlu_params[1]:.2f} + {screlu_params[2]:.2e}\"\n",
    "crelu_text = f\"crelu: y = {crelu_params[0]:.2e} * x^{crelu_params[1]:.2f} + {crelu_params[2]:.2e}\"\n",
    "# Place text in upper right corner with larger font and background\n",
    "ax.text(0.98, 0.98, screlu_text + '\\n' + crelu_text, \n",
    "        transform=ax.transAxes, \n",
    "        verticalalignment='top', \n",
    "        horizontalalignment='right',\n",
    "        fontsize=12,\n",
    "        bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=5))\n",
    "\n",
    "ax.legend(title=\"Configuration\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.set_xticks([2 ** x for x in range(0, 12)])\n",
    "ax.set_xticklabels([2 ** x for x in range(0, 12)])\n",
    "ax.set_xlim(0.5, 8192)\n",
    "min_loss = min(np.min(crelu_extrap), np.min(screlu_extrap))\n",
    "max_loss = max(np.max(crelu_extrap), np.max(screlu_extrap))\n",
    "y_ticks = np.logspace(np.log2(min_loss), np.log2(max_loss), num = 10, base = 2.0)\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(np.round(y_ticks, 4))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"net-size-guantlet-ratings.txt\") as f:\n",
    "    text = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [s.split()[1:5] for s in text]\n",
    "names, _, elos, errors = zip(*data[2:])\n",
    "names = list(map(int, names))\n",
    "elos = list(map(float, elos))\n",
    "errors = list(map(float, errors))\n",
    "up_down_errors = [errors, errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_ncount, neg_losses = zip(*configuration_series[\"screlu-warmupcosinedecay\"][5:])\n",
    "neg_losses = [-l for l in neg_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "ax1co = \"tab:red\"\n",
    "ax2co = \"tab:blue\"\n",
    "\n",
    "# Customize plot\n",
    "ax.set_ylabel(\"Elo\", color=ax1co)\n",
    "ax.set_yticks(list(range(0, 550, 50)))\n",
    "ax.tick_params(axis='y', labelcolor=ax1co)\n",
    "ax.set_xlabel(\"Number of Neurons\")\n",
    "ax.set_xscale(\"log\", base = 2)\n",
    "ax.set_xticks([2 ** (x / 2) for x in range(4 * 2, 14 * 2)])\n",
    "ax.set_xticklabels([2 ** (x // 2) if x % 2 == 0 else None for x in range(4 * 2, 14 * 2)])\n",
    "ax.set_xlim(16, 8192)\n",
    "ax.set_title(\"Elo vs. Net Size\")\n",
    "(lns1, caps, _) = ax.errorbar(names, elos, yerr=up_down_errors, color=ax1co, ecolor=\"black\", elinewidth=1.0, markersize=8, capsize=4, label=\"elo curve\")\n",
    "lns1.set_label(\"elo curve\")\n",
    "for cap in caps:\n",
    "    cap.set_markeredgewidth(1.0)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "ax2.grid(False)\n",
    "lns2 = ax2.plot(neg_ncount, neg_losses, color=ax2co, label=\"(negative) loss curve\")\n",
    "bottom, top = ax2.get_ylim()\n",
    "ax2.set_ylim(bottom=bottom, top=top + 0.00025)\n",
    "ax2.set_ylabel(\"(Negative) Final Loss\", color=ax2co)\n",
    "ax2.tick_params(axis='y', labelcolor=ax2co)\n",
    "\n",
    "lns = [lns1]+lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labs, loc=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
